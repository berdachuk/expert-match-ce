# Local Development Configuration with OpenAI-Compatible Providers
# This file is gitignored and should be customized for your local setup
#
# Configuration:
# - LLM Inference: OpenAI-compatible provider (configure via CHAT_BASE_URL)
# - Embeddings: OpenAI-compatible provider (configure via EMBEDDING_BASE_URL)
# - Reranking: OpenAI-compatible provider (configure via RERANKING_BASE_URL)
#
# To use this configuration, run with: --spring.profiles.active=local
# Or set: export SPRING_PROFILES_ACTIVE=local
#
# Prerequisites:
# - OpenAI-compatible API endpoint (e.g., OpenAI, Azure OpenAI, or other compatible service)
# - API keys configured via environment variables or this file
# - Models available on your OpenAI-compatible provider

CHAT_PROVIDER: openai
CHAT_BASE_URL: http://localhost:11434
# Chat model options:
# - devstral-small-2:24b-cloud (24B, current default)
# - qwen3:30b-a3b-instruct-2507-q4_K_M (30.5B, alternative)
# - qwen3:4b-instruct-2507-q4_K_M (4B, faster)
CHAT_MODEL: devstral-small-2:24b-cloud
CHAT_API_KEY: none

# Embedding configuration - OpenAI-compatible provider
EMBEDDING_PROVIDER: openai
EMBEDDING_BASE_URL: http://localhost:11434
EMBEDDING_MODEL: qwen3-embedding:0.6b
EMBEDDING_API_KEY: none
EMBEDDING_DIMENSIONS: 1024

# Reranking configuration - OpenAI-compatible provider
RERANKING_PROVIDER: openai
RERANKING_BASE_URL: http://localhost:11434
# Reranking can use a chat model - using the same model as chat for consistency
# Reranking model options:
# - devstral-small-2:24b-cloud (24B, current default)
# - qwen3:30b-a3b-instruct-2507-q4_K_M (30.5B, alternative)
# - qwen3:4b-instruct-2507-q4_K_M (4B, faster)
RERANKING_MODEL: devstral-small-2:24b-cloud
RERANKING_TEMPERATURE: 0.1

INGEST_POSTGRES_HOST: localhost
INGEST_POSTGRES_PORT: 5432
INGEST_POSTGRES_DB: aist-tool-networking
INGEST_POSTGRES_PASSWORD: your_password
INGEST_POSTGRES_USER: Auto_EPM-ESP_srv-aist@epam.com

# Enable HTTP request logging to debug LLM API calls
logging:
  level:
    org.springframework.web.client.RestClient: DEBUG
    org.springframework.ai.openai.api.OpenAiApi: DEBUG
    org.springframework.http.client: DEBUG
    # Enable logging for Spring AI ChatClient and tool calls (including Agent Skills)
    org.springframework.ai.chat.client: DEBUG
    org.springframework.ai.chat.client.advisor: DEBUG
    # Enable logging for Agent Skills (Spring AI Agent Utils)
    org.springaicommunity.agent.tools: DEBUG
    org.springaicommunity.agent: DEBUG

server:
  port: 8093
  # Bind to all interfaces (0.0.0.0) to allow remote access
  # This allows access from other machines on the network (e.g., 192.168.0.73)
  address: 0.0.0.0
  # Increase timeout for long-running queries (LLM processing can take time)
  # Default is 30 seconds, increased to 5 minutes for complex queries
  connection-timeout: 300000  # 5 minutes
  # Tomcat-specific timeout settings
  tomcat:
    connection-timeout: 300000  # 5 minutes
    keep-alive-timeout: 300000  # 5 minutes

